---
phase: 02-file-storage-foundation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - supabase/migrations/030_file_attachments.sql
  - supabase/migrations/031_storage_bucket_rls.sql
  - supabase/migrations/032_file_cascade_cleanup.sql
  - supabase/functions/cleanup-expired-files/index.ts
autonomous: true
user_setup: []

must_haves:
  truths:
    - "File metadata table exists with entity polymorphism (qmrl/qmhq)"
    - "Storage bucket 'attachments' is private with file size and type restrictions"
    - "RLS on file_attachments mirrors QMRL/QMHQ access permissions"
    - "RLS on storage.objects allows read/write based on entity access"
    - "Soft-deleted parent entities cascade soft-delete to attached files"
    - "Cleanup function identifies expired soft-deleted files for purge"
    - "Edge Function removes expired storage objects and purges metadata"
  artifacts:
    - path: "supabase/migrations/030_file_attachments.sql"
      provides: "file_attachments table with indexes and RLS"
      contains: "CREATE TABLE"
    - path: "supabase/migrations/031_storage_bucket_rls.sql"
      provides: "Storage bucket and storage.objects RLS policies"
      contains: "INSERT INTO storage.buckets"
    - path: "supabase/migrations/032_file_cascade_cleanup.sql"
      provides: "Cascade triggers and cleanup functions"
      contains: "cascade_soft_delete_files"
    - path: "supabase/functions/cleanup-expired-files/index.ts"
      provides: "Edge Function for full orphan cleanup"
      contains: "storage.from('attachments').remove"
  key_links:
    - from: "file_attachments.entity_id"
      to: "qmrl.id OR qmhq.id"
      via: "polymorphic entity_type column"
      pattern: "entity_type.*entity_id"
    - from: "storage.objects policies"
      to: "file_attachments.storage_path"
      via: "RLS checking metadata table"
      pattern: "storage_path = name"
    - from: "supabase/functions/cleanup-expired-files"
      to: "storage.from('attachments').remove()"
      via: "Edge Function calls storage API"
      pattern: "remove\\(paths\\)"
---

<objective>
Create the database infrastructure for file attachments including metadata table, storage bucket, RLS policies, cascade/cleanup mechanisms, and Edge Function for full orphan cleanup.

Purpose: Establishes the foundational schema that all file operations will rely on, with security policies mirroring entity access and complete orphan prevention.
Output: Three SQL migrations and one Edge Function that when deployed create a fully RLS-protected file storage system with no orphans.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/02-file-storage-foundation/02-CONTEXT.md
@.planning/phases/02-file-storage-foundation/02-RESEARCH.md

@supabase/migrations/027_rls_policies.sql (for RLS patterns and get_user_role() helper)
@supabase/migrations/011_qmhq.sql (for entity structure reference)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create file_attachments table migration</name>
  <files>supabase/migrations/030_file_attachments.sql</files>
  <action>
Create migration file with:

1. **file_attachments table:**
   - id: UUID PRIMARY KEY DEFAULT gen_random_uuid()
   - entity_type: TEXT NOT NULL CHECK (entity_type IN ('qmrl', 'qmhq'))
   - entity_id: UUID NOT NULL (no FK constraint - polymorphic)
   - filename: TEXT NOT NULL (original filename preserved)
   - storage_path: TEXT NOT NULL UNIQUE (path in storage bucket)
   - file_size: BIGINT NOT NULL (size in bytes)
   - mime_type: TEXT NOT NULL
   - uploaded_by: UUID NOT NULL REFERENCES public.users(id)
   - uploaded_at: TIMESTAMPTZ DEFAULT NOW()
   - deleted_at: TIMESTAMPTZ (soft delete timestamp)
   - deleted_by: UUID REFERENCES public.users(id)
   - created_at: TIMESTAMPTZ DEFAULT NOW()
   - updated_at: TIMESTAMPTZ DEFAULT NOW()

2. **Indexes:**
   - idx_file_attachments_entity ON (entity_type, entity_id) WHERE deleted_at IS NULL
   - idx_file_attachments_storage_path ON (storage_path) for RLS performance
   - idx_file_attachments_uploaded_by ON (uploaded_by)

3. **Enable RLS on file_attachments**

4. **RLS Policies (mirror entity access):**
   - SELECT: Users can view files if they can view the parent entity
     - Admin, Quartermaster, Finance, Inventory, Proposal, Frontline: all non-deleted files
     - Requester: only files on entities they own (via requester_id)
   - INSERT: Users who can edit the parent entity can upload files
     - Admin, Quartermaster can upload to any entity
     - Proposal, Frontline can upload to qmrl/qmhq
     - Requester can upload to own qmrl only
   - DELETE (soft delete via UPDATE): Admin and Quartermaster only (per CONTEXT.md decision)

Use get_user_role(), owns_qmrl(), owns_qmhq() helpers from 027_rls_policies.sql.

Include header comment explaining the migration purpose.
  </action>
  <verify>
Run: `npx supabase db reset` and verify migration applies without errors.
Check: `\d file_attachments` in psql shows correct columns.
Check: RLS policies exist with `\dp file_attachments`.
  </verify>
  <done>
file_attachments table created with proper columns, indexes, and RLS policies mirroring entity access.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create storage bucket and storage.objects RLS policies</name>
  <files>supabase/migrations/031_storage_bucket_rls.sql</files>
  <action>
Create migration file with:

1. **Create 'attachments' bucket:**
   ```sql
   INSERT INTO storage.buckets (id, name, public, file_size_limit, allowed_mime_types)
   VALUES (
     'attachments',
     'attachments',
     false,  -- Private bucket
     26214400,  -- 25MB in bytes
     ARRAY[
       'image/jpeg', 'image/png', 'image/gif', 'image/webp',
       'application/pdf',
       'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
       'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
       'application/vnd.openxmlformats-officedocument.presentationml.presentation',
       'application/msword',
       'application/vnd.ms-excel',
       'application/vnd.ms-powerpoint'
     ]
   )
   ON CONFLICT (id) DO UPDATE SET
     file_size_limit = EXCLUDED.file_size_limit,
     allowed_mime_types = EXCLUDED.allowed_mime_types;
   ```

2. **RLS Policies on storage.objects:**

   DROP existing policies for 'attachments' bucket if any.

   **SELECT policy:** Users can download files if:
   - File exists in file_attachments with matching storage_path
   - File is not soft-deleted (deleted_at IS NULL)
   - User can access parent entity (same logic as file_attachments SELECT)

   **INSERT policy:** Users can upload files if:
   - They have permission to add files to the target entity
   - Check based on path pattern: 'qmrl/{entity_id}/*' or 'qmhq/{entity_id}/*'
   - Admin, Quartermaster: any entity
   - Proposal, Frontline: qmrl/qmhq entities
   - Requester: own qmrl only

   **DELETE policy:** Admin and Quartermaster only (for cleanup job)

Use storage.foldername(name) to extract entity type and ID from path.
Path format: '{entity_type}/{entity_id}/{filename}_{timestamp}.ext'

Include comments explaining each policy.
  </action>
  <verify>
Run: `npx supabase db reset` to apply migration.
Check: Bucket exists with `SELECT * FROM storage.buckets WHERE id = 'attachments'`.
Check: Storage policies exist with `SELECT * FROM pg_policies WHERE tablename = 'objects'`.
  </verify>
  <done>
Storage bucket 'attachments' created with 25MB limit and MIME type restrictions. RLS policies on storage.objects enforce entity-based access control.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create cascade soft-delete triggers and cleanup function</name>
  <files>supabase/migrations/032_file_cascade_cleanup.sql</files>
  <action>
Create migration file with:

1. **Cascade soft-delete function:**
   ```sql
   CREATE OR REPLACE FUNCTION public.cascade_soft_delete_files()
   RETURNS TRIGGER AS $$
   BEGIN
     IF OLD.is_active = true AND NEW.is_active = false THEN
       UPDATE public.file_attachments
       SET
         deleted_at = NOW(),
         deleted_by = auth.uid(),
         updated_at = NOW()
       WHERE
         entity_type = TG_ARGV[0]
         AND entity_id = NEW.id
         AND deleted_at IS NULL;
     END IF;
     RETURN NEW;
   END;
   $$ LANGUAGE plpgsql SECURITY DEFINER;
   ```

2. **Apply triggers to QMRL and QMHQ:**
   ```sql
   CREATE TRIGGER qmrl_cascade_soft_delete_files
   AFTER UPDATE OF is_active ON public.qmrl
   FOR EACH ROW
   EXECUTE FUNCTION public.cascade_soft_delete_files('qmrl');

   CREATE TRIGGER qmhq_cascade_soft_delete_files
   AFTER UPDATE OF is_active ON public.qmhq
   FOR EACH ROW
   EXECUTE FUNCTION public.cascade_soft_delete_files('qmhq');
   ```

3. **Cleanup helper functions (for Edge Function):**
   ```sql
   -- Get expired file paths (30 day grace period)
   CREATE OR REPLACE FUNCTION public.get_expired_file_paths()
   RETURNS TABLE(id UUID, storage_path TEXT) AS $$
   BEGIN
     RETURN QUERY
     SELECT fa.id, fa.storage_path
     FROM public.file_attachments fa
     WHERE fa.deleted_at IS NOT NULL
       AND fa.deleted_at < NOW() - INTERVAL '30 days';
   END;
   $$ LANGUAGE plpgsql SECURITY DEFINER;

   -- Purge metadata after storage objects deleted
   CREATE OR REPLACE FUNCTION public.purge_expired_file_metadata()
   RETURNS INTEGER AS $$
   DECLARE
     deleted_count INTEGER;
   BEGIN
     DELETE FROM public.file_attachments
     WHERE deleted_at IS NOT NULL
       AND deleted_at < NOW() - INTERVAL '30 days';
     GET DIAGNOSTICS deleted_count = ROW_COUNT;
     RETURN deleted_count;
   END;
   $$ LANGUAGE plpgsql SECURITY DEFINER;
   ```

Include header comment explaining the cascade behavior and 30-day grace period.
  </action>
  <verify>
Run: `npx supabase db reset` to apply all migrations.
Test cascade: Update qmrl.is_active = false, verify file_attachments.deleted_at is set.
Test functions: SELECT * FROM get_expired_file_paths() runs without error.
  </verify>
  <done>
Cascade soft-delete triggers active on QMRL and QMHQ. Cleanup functions ready for Edge Function.
  </done>
</task>

<task type="auto">
  <name>Task 4: Create Edge Function for full orphan cleanup</name>
  <files>supabase/functions/cleanup-expired-files/index.ts</files>
  <action>
Create Edge Function that orchestrates complete file cleanup (storage + metadata):

1. **Function structure:**
   ```typescript
   import { serve } from 'https://deno.land/std@0.168.0/http/server.ts'
   import { createClient } from 'https://esm.sh/@supabase/supabase-js@2'

   serve(async (req) => {
     // Only allow POST requests (for scheduled invocation or manual trigger)
     if (req.method !== 'POST') {
       return new Response('Method not allowed', { status: 405 })
     }

     // Create Supabase client with service role for admin operations
     const supabaseUrl = Deno.env.get('SUPABASE_URL')!
     const serviceRoleKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!
     const supabase = createClient(supabaseUrl, serviceRoleKey)

     // Step 1: Get expired file paths from metadata
     const { data: expiredFiles, error: queryError } = await supabase
       .rpc('get_expired_file_paths')

     if (queryError) {
       return new Response(JSON.stringify({ error: queryError.message }), {
         status: 500,
         headers: { 'Content-Type': 'application/json' }
       })
     }

     if (!expiredFiles || expiredFiles.length === 0) {
       return new Response(JSON.stringify({
         message: 'No expired files to clean up',
         deleted: 0
       }), {
         status: 200,
         headers: { 'Content-Type': 'application/json' }
       })
     }

     // Step 2: Remove storage objects
     const paths = expiredFiles.map((f: { storage_path: string }) => f.storage_path)
     const { error: removeError } = await supabase.storage
       .from('attachments')
       .remove(paths)

     if (removeError) {
       return new Response(JSON.stringify({
         error: `Storage removal failed: ${removeError.message}`,
         attempted: paths.length
       }), {
         status: 500,
         headers: { 'Content-Type': 'application/json' }
       })
     }

     // Step 3: Purge metadata records
     const { data: purgedCount, error: purgeError } = await supabase
       .rpc('purge_expired_file_metadata')

     if (purgeError) {
       return new Response(JSON.stringify({
         error: `Metadata purge failed: ${purgeError.message}`,
         storageRemoved: paths.length
       }), {
         status: 500,
         headers: { 'Content-Type': 'application/json' }
       })
     }

     return new Response(JSON.stringify({
       message: 'Cleanup completed successfully',
       storageObjectsRemoved: paths.length,
       metadataRecordsPurged: purgedCount
     }), {
       status: 200,
       headers: { 'Content-Type': 'application/json' }
     })
   })
   ```

2. **Include header comment:**
   ```typescript
   /**
    * cleanup-expired-files Edge Function
    *
    * Orchestrates complete orphan cleanup:
    * 1. Queries get_expired_file_paths() for files soft-deleted > 30 days ago
    * 2. Removes storage objects from 'attachments' bucket
    * 3. Purges metadata records via purge_expired_file_metadata()
    *
    * Invoke via:
    * - Manual: POST to function URL
    * - Scheduled: pg_cron or external scheduler calling function URL
    *
    * Requires SUPABASE_SERVICE_ROLE_KEY for admin storage operations.
    */
   ```

This ensures "no orphans" by removing both storage objects AND metadata.
  </action>
  <verify>
Run: `npx supabase functions serve cleanup-expired-files` to test locally.
Test: `curl -X POST http://localhost:54321/functions/v1/cleanup-expired-files` returns success response.
Verify: Function imports resolve and type-checks.
  </verify>
  <done>
Edge Function created that orchestrates full cleanup: get paths -> storage.remove() -> purge metadata. No orphan files possible.
  </done>
</task>

</tasks>

<verification>
After all tasks complete:

1. **Schema verification:**
   ```bash
   npx supabase db reset
   ```
   All 3 migrations should apply without errors.

2. **Table structure:**
   - file_attachments table exists with correct columns
   - Indexes created for entity lookup and storage_path

3. **Bucket configuration:**
   - 'attachments' bucket is private
   - file_size_limit = 26214400 (25MB)
   - allowed_mime_types includes all required types

4. **RLS active:**
   - file_attachments has RLS enabled
   - storage.objects has policies for 'attachments' bucket

5. **Triggers active:**
   - qmrl_cascade_soft_delete_files trigger exists
   - qmhq_cascade_soft_delete_files trigger exists

6. **Edge Function:**
   - cleanup-expired-files function exists and serves
   - Returns success response on POST
</verification>

<success_criteria>
- All 3 migrations apply cleanly on `npx supabase db reset`
- file_attachments table has entity_type, entity_id, storage_path columns
- Storage bucket 'attachments' exists with 25MB limit
- RLS policies enforce entity-based file access
- Cascade triggers soft-delete files when parent entity deactivated
- Cleanup functions ready for Edge Function
- Edge Function removes storage objects AND purges metadata (no orphans)
</success_criteria>

<output>
After completion, create `.planning/phases/02-file-storage-foundation/02-01-SUMMARY.md`
</output>
